{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552e1e38",
   "metadata": {},
   "source": [
    "## Preprocess and save training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27cc7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "\n",
    "from tree_parser import file_contents, meta_math_database\n",
    "\n",
    "# from my_utils import print_proof_props_graph, get_proof_steps, print_ident_proof, print_proof_linear_steps\n",
    "# from my_utils import get_proof_steps_graph, print_proof_steps_graph\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "from expanding import construct_proof, expand_all_nodes_with_depth\n",
    "\n",
    "# from collections import defaultdict\n",
    "\n",
    "# import glob\n",
    "\n",
    "# import os\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "# from expanding import PStep, construct_proof\n",
    "# from theorem_database import TheoremDatabase\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2a455c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included 3651825 tokens from ../../data/set_mod.mm\n",
      "proposition: 7000CPU times: user 1min 34s, sys: 19.7 s, total: 1min 53s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = file_contents(\"../../data/set_mod.mm\")\n",
    "database = meta_math_database(text,n=7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee647e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opoe not in database.\n",
      "omoe not in database.\n",
      "epee not in database.\n",
      "emee not in database.\n",
      "oddp1eveni not in database.\n",
      "dvdsadd2b not in database.\n",
      "opoeALTV not in database.\n",
      "omoeALTV not in database.\n"
     ]
    }
   ],
   "source": [
    "test_props = [\n",
    "    \"dfss3\",\n",
    "    \"dfss2\",\n",
    "    \"dfss\",\n",
    "    \"t1lucas\",\n",
    "    \"t2lucas\",\n",
    "    \"ssun1\",\n",
    "    \"t4lucas\",\n",
    "    \"t5lucas\",\n",
    "    \"opoe\",\n",
    "    \"omoe\",\n",
    "    \"pwin\",\n",
    "    \"inidm\",\n",
    "    \"in0\",\n",
    "    \"sstr\",\n",
    "    \"ssequn1\",\n",
    "    \"pwunss\",\n",
    "    \"epee\",\n",
    "    \"emee\",\n",
    "    \"oddp1eveni\",\n",
    "    \"dvdsadd2b\",\n",
    "    \"opoeALTV\",\n",
    "    \"omoeALTV\"\n",
    "]\n",
    "\n",
    "#Check if something is absent\n",
    "for t in test_props:\n",
    "    if t not in database.propositions.keys():\n",
    "        print(f\"{t} not in database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c3439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6986\n"
     ]
    }
   ],
   "source": [
    "train_props = [p for p in database.propositions.keys() if p not in test_props]\n",
    "print(len(train_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "196fab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5588 1398\n"
     ]
    }
   ],
   "source": [
    "train_props, valid_props = train_test_split(train_props, test_size=0.2, random_state=2)\n",
    "print(len(train_props), len(valid_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eaf9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_all_nodes_with_depth_and_filter(root, target_depth, filter_list):\n",
    "    if root.depth == target_depth and root.label in filter_list:\n",
    "        root = root.expand()\n",
    "    \n",
    "    for i in root.inputs:\n",
    "        expand_all_nodes_with_depth_and_filter(i, target_depth, filter_list)\n",
    "        \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aacdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prop_label = \"dfss2\"#train_props[987]\n",
    "# expand_filter = train_props\n",
    "\n",
    "# prop_dataset = {\n",
    "#     'id':prop.number,\n",
    "#     'prop': prop_label,\n",
    "#     'steps':[],\n",
    "#     'links':[]\n",
    "# }\n",
    "\n",
    "# prop = database.propositions[prop_label]\n",
    "\n",
    "# prop_proof = construct_proof(prop)\n",
    "\n",
    "# for s in prop_proof.get_steps_df():\n",
    "#     print(s.label, s.label in expand_filter)\n",
    "\n",
    "\n",
    "\n",
    "# prop_proof = expand_all_nodes_with_depth_and_filter(prop_proof, 0, expand_filter)\n",
    "\n",
    "\n",
    "# prop_dataset\n",
    "\n",
    "# prop_proof.print_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "718dcdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_dataset_with_filter(prop_label, filter_list):\n",
    "    prop = database.propositions[prop_label]\n",
    "    \n",
    "    prop_dataset = {\n",
    "        'id':prop.number,\n",
    "        'prop': prop_label,\n",
    "        'steps':[],\n",
    "        'links':[]\n",
    "    }\n",
    "    \n",
    "    prop_proof = construct_proof(prop)\n",
    "    prop_proof = expand_all_nodes_with_depth_and_filter(prop_proof, 0, filter_list)\n",
    "\n",
    "    #Populate step numbers\n",
    "    next_step_n = 0\n",
    "    \n",
    "    for s in prop_proof.get_steps_df(): \n",
    "        next_step_n += 1\n",
    "        s._step_num = next_step_n\n",
    "    \n",
    "    #Populate data\n",
    "    \n",
    "    _no_zero_labels = True \n",
    "    #This flag is necessary to remove from the dataset propositions which every label is true\n",
    "    #All labels true doesnt contribute much to the train/validation\n",
    "    \n",
    "    for s in prop_proof.get_steps_df():\n",
    "        #Since negative class is some depth bigger than 0, in case we have some, set this to false\n",
    "        if s.statement_depth > 0: _no_zero_labels = False\n",
    "        \n",
    "        prop_dataset[\"steps\"].append((\n",
    "            s._step_num,\n",
    "            s.label,\n",
    "            s.raw_statement,\n",
    "            s.raw_prop_statement,\n",
    "            int(s.statement_depth == 0)\n",
    "        ))\n",
    "        \n",
    "        for child_s in s.inputs:\n",
    "            prop_dataset[\"links\"].append((child_s._step_num, s._step_num))\n",
    "        \n",
    "    if _no_zero_labels:\n",
    "        raise Exception(f\"Only positive classes in {prop_label}.\")\n",
    "        \n",
    "    return prop_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f35c48d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5588/5588\n",
      "5108\n",
      "248\n",
      "CPU times: user 2min 38s, sys: 42 s, total: 3min 20s\n",
      "Wall time: 5min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Process training data\n",
    "\n",
    "train_props_data = []\n",
    "train_failed_props = []\n",
    "\n",
    "for i, p in enumerate(train_props):\n",
    "    print(f\"\\r{i+1}/{len(train_props)}\", end=\"\")\n",
    "    \n",
    "    if len(database.propositions[p].entails_proof_steps) == 0:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        train_props_data.append(get_prop_dataset_with_filter(p, train_props))\n",
    "    except:\n",
    "        train_failed_props.append(p)\n",
    "      \n",
    "print()\n",
    "print(len(train_props_data))\n",
    "print(len(train_failed_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13021bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1398/1398\n",
      "817\n",
      "530\n",
      "CPU times: user 3.7 s, sys: 352 ms, total: 4.05 s\n",
      "Wall time: 4.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Process validation data\n",
    "\n",
    "valid_props_data = []\n",
    "valid_failed_props = []\n",
    "\n",
    "for i, p in enumerate(valid_props):\n",
    "    print(f\"\\r{i+1}/{len(valid_props)}\", end=\"\")\n",
    "    \n",
    "    if len(database.propositions[p].entails_proof_steps) == 0:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        valid_props_data.append(get_prop_dataset_with_filter(p, valid_props))\n",
    "    except:\n",
    "        valid_failed_props.append(p)\n",
    "      \n",
    "print()\n",
    "print(len(valid_props_data))\n",
    "print(len(valid_failed_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a169775",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "os.mkdir(f\"../../data/datasets/{ts}\")\n",
    "\n",
    "json.dump(train_props_data, open(f\"../../data/datasets/{ts}/train.json\", \"w\"))\n",
    "json.dump(valid_props_data, open(f\"../../data/datasets/{ts}/valid.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc42b83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(f\"../../data/datasets/{ts}/test.txt\", \"w\").write(\"\\n\".join(test_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73224048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
