{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f20b52a",
   "metadata": {},
   "source": [
    "## Determinar quais provas e quais passos vao ser usados para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee392800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_parser import file_contents, meta_math_database\n",
    "\n",
    "from my_utils import print_proof_props_graph, get_proof_steps, print_ident_proof, print_proof_linear_steps\n",
    "from my_utils import get_proof_steps_graph, print_proof_steps_graph\n",
    "\n",
    "\n",
    "from expanding import construct_proof, expand_proof_step_ps\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from expanding import PStep, construct_proof\n",
    "from theorem_database import TheoremDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b1bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdb = TheoremDatabase(\"tdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d50b4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included 3651825 tokens from set_mod.mm\n",
      "proposition: 5000CPU times: user 22.8 s, sys: 426 ms, total: 23.2 s\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = file_contents(\"set_mod.mm\")\n",
    "#database = meta_math_database(text,n=16080)\n",
    "database = meta_math_database(text,n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b932402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theorem_complexity(theorem_name):\n",
    "    theorem = tdb[theorem_name]\n",
    "    \n",
    "    assert theorem != None, f\"Error while getting theorem '{theorem_name}'.\"\n",
    "    \n",
    "    if \"complexity\" not in theorem:\n",
    "        t_name = theorem[\"theorem\"]\n",
    "        print(f\"Complexity of {t_name} not found. Getting complexity...\")\n",
    "        \n",
    "        if len(theorem[\"steps\"]) == 0:\n",
    "            theorem[\"complexity\"] = 1\n",
    "        else:\n",
    "            theorem[\"complexity\"] = sum([get_theorem_complexity(tt[\"theorem\"]) for tt in theorem[\"steps\"]])\n",
    "            \n",
    "    return theorem[\"complexity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3c8b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10727"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_theorem_complexity(\"bitr4i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50fab86",
   "metadata": {},
   "source": [
    "### Intensity\n",
    "Intensity measures how much a formula summarizes information from the leaf ancestors in its derivation tree. Formulae that summarize a lot of information are more interesting. \n",
    "The plurality score of a formula (or set of formulae) is number of function and predicate symbols in the formula divided by the number of distinct function and predicate symbols in the formula. Plurality measures the extent to which symbols are repeated in the formula. The intensity score of a formula is the plurality of its leaf ancestors divided by the plurality of the formula itself. A higher score is better. Intensity works well with complexity – interesting things are often compact,\n",
    "which means intense but not complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a39cbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7\n",
      "2.8877005347593583\n",
      "1.625\n",
      "2.735042735042735\n"
     ]
    }
   ],
   "source": [
    "def get_plurality(statement, no_parenthesis=False):\n",
    "    exc_symbols = [\"(\", \")\"] if no_parenthesis else []\n",
    "    return count_tokens(statement, exc_symbols) / count_tokens(statement, exc_symbols, distinct=True) \n",
    "\n",
    "def count_tokens(statement, excluded_tokens=[], distinct=False):\n",
    "    tokens = [t for t in statement.split(\" \") if t not in excluded_tokens]\n",
    "    if distinct:\n",
    "        count = len(set(tokens))\n",
    "    else:\n",
    "        count = len(tokens)\n",
    "    return count\n",
    "\n",
    "def get_intensity(step_statement, prev_statements, no_parenthesis=False):\n",
    "    #In case prev_statements is empty, it will still work because count_tokens will return 1\n",
    "    #due to empty tokens list and hence plurality will return 1/1 = 1.\n",
    "    \n",
    "    #leaves_plur = sum([get_intensity(s) for s in prev_steps])\n",
    "    leaves_plur = get_plurality(\" \".join([s for s in prev_statements]), no_parenthesis)\n",
    "    form_plur = get_plurality(step_statement, no_parenthesis)\n",
    "    return leaves_plur / form_plur\n",
    "\n",
    "prop_proof = construct_proof(database.propositions[\"dfss2\"])\n",
    "print(get_plurality(prop_proof.statement))\n",
    "print(get_intensity(prop_proof.statement, [s.statement for s in prop_proof.inputs]))\n",
    "\n",
    "print(get_plurality(prop_proof.statement, True))\n",
    "print(get_intensity(prop_proof.statement, [s.statement for s in prop_proof.inputs], True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b3691c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_plurality(prop_proof.statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa5fa510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( A ⊆ B ↔ ∀ x ( x ∈ A → x ∈ B ) )'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_proof.statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a937d535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( A ⊆ B ↔ ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) ) ( ∀ x ( x ∈ A → x ∈ B ) ↔ ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) )'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([s.statement for s in prop_proof.inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56dcaed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.909090909090909"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_plurality(\" \".join([s.statement for s in prop_proof.inputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96ec3bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <PStep:mp2 ⊢ ( A ⊆ B ↔ ∀ x ( x ∈ A → x ∈ B ) )> 5.153846153846154\n",
      " |  <PStep:sylib ⊢ ( A ⊆ B → ∀ x ( x ∈ A → x ∈ B ) )> 2.393162393162393\n",
      " |  |  <PStep:biimpi ⊢ ( A ⊆ B → ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) )> 1.125\n",
      " |  |  |  <PStep:3bitri ⊢ ( A ⊆ B ↔ ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) )> 1.990950226244344\n",
      " |  |  |  |  <PStep:dfss ⊢ ( A ⊆ B ↔ A = ( A ∩ B ) )> 0.6666666666666666\n",
      " |  |  |  |  <PStep:eqeq2i ⊢ ( A = ( A ∩ B ) ↔ A = { x | ( x ∈ A ∧ x ∈ B ) } )> 0.868421052631579\n",
      " |  |  |  |  |  <PStep:df-in ⊢ ( A ∩ B ) = { x | ( x ∈ A ∧ x ∈ B ) }> 0.6666666666666666\n",
      " |  |  |  |  <PStep:abeq2 ⊢ ( A = { x | ( x ∈ A ∧ x ∈ B ) } ↔ ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) )> 0.4074074074074074\n",
      " |  |  <PStep:bicomi ⊢ ( ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) ↔ ∀ x ( x ∈ A → x ∈ B ) )> 1.0\n",
      " |  |  |  <PStep:albii ⊢ ( ∀ x ( x ∈ A → x ∈ B ) ↔ ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) )> 0.9440993788819876\n",
      " |  |  |  |  <PStep:pm4.71 ⊢ ( ( x ∈ A → x ∈ B ) ↔ ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) )> 0.3684210526315789\n",
      " |  <PStep:sylibr ⊢ ( ∀ x ( x ∈ A → x ∈ B ) → A ⊆ B )> 2.393162393162393\n",
      " |  |  <PStep:biimpri ⊢ ( ∀ x ( x ∈ A → x ∈ B ) → ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) )> 1.0\n",
      " |  |  |  <PStep:bicomi ⊢ ( ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) ↔ ∀ x ( x ∈ A → x ∈ B ) )> 1.0\n",
      " |  |  |  |  <PStep:albii ⊢ ( ∀ x ( x ∈ A → x ∈ B ) ↔ ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) )> 0.9440993788819876\n",
      " |  |  |  |  |  <PStep:pm4.71 ⊢ ( ( x ∈ A → x ∈ B ) ↔ ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) )> 0.3684210526315789\n",
      " |  |  <PStep:3bitri ⊢ ( A ⊆ B ↔ ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) )> 1.990950226244344\n",
      " |  |  |  <PStep:dfss ⊢ ( A ⊆ B ↔ A = ( A ∩ B ) )> 0.6666666666666666\n",
      " |  |  |  <PStep:eqeq2i ⊢ ( A = ( A ∩ B ) ↔ A = { x | ( x ∈ A ∧ x ∈ B ) } )> 0.868421052631579\n",
      " |  |  |  |  <PStep:df-in ⊢ ( A ∩ B ) = { x | ( x ∈ A ∧ x ∈ B ) }> 0.6666666666666666\n",
      " |  |  |  <PStep:abeq2 ⊢ ( A = { x | ( x ∈ A ∧ x ∈ B ) } ↔ ∀ x ( x ∈ A ↔ ( x ∈ A ∧ x ∈ B ) ) )> 0.4074074074074074\n",
      " |  <PStep:bi3 ⊢ ( ( A ⊆ B → ∀ x ( x ∈ A → x ∈ B ) ) → ( ( ∀ x ( x ∈ A → x ∈ B ) → A ⊆ B ) → ( A ⊆ B ↔ ∀ x ( x ∈ A → x ∈ B ) ) ) )> 0.1951219512195122\n"
     ]
    }
   ],
   "source": [
    "def print_linear(stp, ident=0):\n",
    "    int_value = get_intensity(stp.statement, [s.statement for s in stp.inputs], True)\n",
    "    print(\" | \" * ident, stp, int_value)\n",
    "    for cs in stp.inputs:\n",
    "        print_linear(cs, ident+1)\n",
    "        \n",
    "prop_proof = construct_proof(database.propositions[\"dfss2\"])\n",
    "prop_proof = prop_proof.expand().get_root_step()\n",
    "prop_proof = prop_proof.expand().get_root_step()\n",
    "prop_proof = prop_proof.expand().get_root_step()\n",
    "print_linear(prop_proof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34b2c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseClf:\n",
    "    def auc_score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return roc_auc_score(y, predictions)\n",
    "    \n",
    "class IntensityClassifier(BaseClf):\n",
    "    def predict(self, X):\n",
    "        predictions = list()\n",
    "        for s in X:\n",
    "            predictions.append(get_plurality(s.statement, [ss.statement for ss in s.inputs]))\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        \n",
    "        #Get max value and normalize by it\n",
    "        max_pred = predictions.max()\n",
    "        predictions = predictions / max_pred\n",
    "        \n",
    "        #According to the IDV paper, the higher the plurality the better. Since we want\n",
    "        # class 1 to be the class to be hidden, we have to invert the normalized plurality.\n",
    "        predictions = 1 - predictions\n",
    "        return predictions\n",
    "        \n",
    "    \n",
    "class ObviousnessClassifier(BaseClf):\n",
    "    def predict(self, X):\n",
    "        try:\n",
    "            predictions = list()\n",
    "            for s in X:\n",
    "                predictions.append(get_theorem_complexity(s.label))\n",
    "\n",
    "            predictions = np.array(predictions)\n",
    "            #Here the smallest complexity should receive value of 1\n",
    "            #so we can signalize it to be hidden\n",
    "\n",
    "            #Here the biggest complexity becomes 1\n",
    "            predictions = predictions / predictions.max()\n",
    "            \n",
    "            #So them we invert it and put as 0\n",
    "            predictions = 1 - predictions\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "        return predictions\n",
    "            \n",
    "class WeightClassifier(BaseClf):   \n",
    "    def predict(self, X):\n",
    "        predictions = list()\n",
    "        for s in X:\n",
    "            predictions.append(len(s.statement.split(\" \")))\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        \n",
    "        #Get max value and normalize by it\n",
    "        max_pred = predictions.max()\n",
    "        predictions = predictions/max_pred\n",
    "        \n",
    "        # The way it is the largest statement will get the value of 1\n",
    "        # Here we will treat the positive class as the statement to be removed\n",
    "        # In this classifier we want to keep only the small expressions      \n",
    "        return predictions\n",
    "    \n",
    "class ComplexityClassifier(BaseClf):   \n",
    "    def predict(self, X):\n",
    "        predictions = list()\n",
    "        for s in X:\n",
    "            predictions.append(len(set(s.statement.split(\" \"))))\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        \n",
    "        #Get max value and normalize by it\n",
    "        max_pred = predictions.max()\n",
    "        predictions = predictions / max_pred\n",
    "        \n",
    "        # The way it is the largest statement will get the value of 1\n",
    "        # Here we will treat the positive class as the statement to be removed\n",
    "        # In this classifier we want to keep only the small expressions      \n",
    "        return predictions\n",
    "    \n",
    "class TopologyClassifier(BaseClf):\n",
    "    #This classifier aimed to sample nodes uniformilly accross\n",
    "    #the tree topology, however it seems that the random classifier already\n",
    "    #does that fundamentally.\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "class EdgesCountClassifier(BaseClf):\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "class RandomClassifier(BaseClf):\n",
    "    def predict(self, X):\n",
    "        return np.random.random(len(X))\n",
    "\n",
    "#Single label classifiers doesnt work properly because AUC doesnt work with single classifications\n",
    "# class ZeroClassifier(BaseClf):\n",
    "#     def predict(self, X):\n",
    "#         return np.zeros(len(X))\n",
    "    \n",
    "# class OnesClassifier(BaseClf):\n",
    "#     def predict(self, X):\n",
    "#         return np.ones(len(X))\n",
    "    \n",
    "rand_clf = RandomClassifier()\n",
    "weight_clf = WeightClassifier()\n",
    "obvious_clf = ObviousnessClassifier()\n",
    "comp_clf = ComplexityClassifier()\n",
    "inten_clf = IntensityClassifier()\n",
    "#zero_clf = ZeroClassifier()\n",
    "#ones_clf = OnesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2393de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messed_prop_auc(prop, score_method=None, n_steps=50, n_expansions=20):\n",
    "    \"\"\"\n",
    "        Generate random expansions to check how the score method can detect additional steps.\n",
    "    \"\"\"\n",
    "    \n",
    "    auc_values = []\n",
    "    for _ in range(n_steps):\n",
    "\n",
    "        prop_proof = construct_proof(database.propositions[prop])\n",
    "        gt_statements = [s.statement for s in prop_proof.get_steps_df()]\n",
    "\n",
    "        #Randomly expand steps\n",
    "        for i in range(n_expansions):\n",
    "            prop_proof = random.choice(prop_proof.get_steps_df()).expand().get_root_step()\n",
    "\n",
    "        prop_steps = prop_proof.get_steps_df()\n",
    "        #Everything within the original statements should not be hidden (class 0)\n",
    "        prop_ys = [int(s.statement not in gt_statements) for s in prop_steps]\n",
    "        \n",
    "        try:\n",
    "            auc_value = score_method(prop_steps, prop_ys)\n",
    "        except Exception as e:\n",
    "            print(prop_ys)\n",
    "            raise e\n",
    "        auc_values.append(auc_value)\n",
    "\n",
    "    return np.mean(auc_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e0b2f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21254581204666437\n",
      "0.4848909851246348\n",
      "0.7652371053219642\n",
      "0.5055632698176888\n",
      "CPU times: user 2.61 s, sys: 54.2 ms, total: 2.67 s\n",
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "prop_label = \"dfss2\"\n",
    "\n",
    "print(get_messed_prop_auc(prop_label, inten_clf.auc_score, 50, 20))\n",
    "print(get_messed_prop_auc(prop_label, comp_clf.auc_score, 50, 20))\n",
    "#print(get_messed_prop_auc(prop_label, obvious_clf.auc_score, 50, 20))\n",
    "print(get_messed_prop_auc(prop_label, weight_clf.auc_score, 50, 20))\n",
    "print(get_messed_prop_auc(prop_label, rand_clf.auc_score, 50, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "14703876",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l2/7llyhwlx5nd60gwdz55p43cr0000gn/T/ipykernel_50664/3782597539.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bitr4i\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "database.propositions[\"bitr4i\"].hyps[5].tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "18b3412a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10727"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdb[\"bitr4i\"][\"complexity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1bdbfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opoe not in database.\n",
      "omoe not in database.\n",
      "dvdsadd2b not in database.\n"
     ]
    }
   ],
   "source": [
    "theorem_list = [\n",
    "    \"dfss3\",\n",
    "    \"dfss2\",\n",
    "    \"dfss\",\n",
    "    \"t1lucas\",\n",
    "    \"t2lucas\",\n",
    "    \"ssun1\",\n",
    "    \"t4lucas\",\n",
    "    \"t5lucas\",\n",
    "    \"opoe\",\n",
    "    \"omoe\",\n",
    "    \"pwin\",\n",
    "    \"inidm\",\n",
    "    \"in0\",\n",
    "    \"sstr\",\n",
    "    \"ssequn1\",\n",
    "    \"pwunss\",\n",
    "    #\"epee\",\n",
    "    #\"emee\",\n",
    "    #\"oddp1eveni\",\n",
    "    \"dvdsadd2b\",\n",
    "    #\"opoeALTV\",\n",
    "    #\"omoeALTV\"\n",
    "]\n",
    "\n",
    "#Ensure everything exists\n",
    "for t in theorem_list:\n",
    "    if t not in database.propositions.keys():\n",
    "        print(f\"{t} not in database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bc2cb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 17/17 [00:13<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2699823328186746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "auc_vals = []\n",
    "for t in tqdm(theorem_list):\n",
    "    if t in database.propositions.keys():\n",
    "        auc_val = get_messed_prop_auc(t, inten_clf.auc_score, 50, 20)\n",
    "        auc_vals.append(auc_val)\n",
    "    \n",
    "print(np.mean(auc_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0af67be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 17/17 [00:09<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7199242636429144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "auc_vals = []\n",
    "for t in tqdm(theorem_list):\n",
    "    if t in database.propositions.keys():\n",
    "        auc_val = get_messed_prop_auc(t, comp_clf.auc_score, 50, 20)\n",
    "        auc_vals.append(auc_val)\n",
    "    \n",
    "print(np.mean(auc_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f04c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/17 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Error while getting theorem 'bi1'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l2/7llyhwlx5nd60gwdz55p43cr0000gn/T/ipykernel_41133/495320940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheorem_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropositions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mauc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_messed_prop_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobvious_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mauc_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l2/7llyhwlx5nd60gwdz55p43cr0000gn/T/ipykernel_41133/1299228373.py\u001b[0m in \u001b[0;36mget_messed_prop_auc\u001b[0;34m(prop, score_method, n_steps, n_expansions)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mauc_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l2/7llyhwlx5nd60gwdz55p43cr0000gn/T/ipykernel_41133/1299228373.py\u001b[0m in \u001b[0;36mget_messed_prop_auc\u001b[0;34m(prop, score_method, n_steps, n_expansions)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mauc_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l2/7llyhwlx5nd60gwdz55p43cr0000gn/T/ipykernel_41133/779955230.py\u001b[0m in \u001b[0;36mauc_score\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBaseClf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l2/7llyhwlx5nd60gwdz55p43cr0000gn/T/ipykernel_41133/779955230.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l2/7llyhwlx5nd60gwdz55p43cr0000gn/T/ipykernel_41133/779955230.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_theorem_complexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l2/7llyhwlx5nd60gwdz55p43cr0000gn/T/ipykernel_41133/1154560960.py\u001b[0m in \u001b[0;36mget_theorem_complexity\u001b[0;34m(theorem_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtheorem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtheorem_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtheorem\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Error while getting theorem '{theorem_name}'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"complexity\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtheorem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Error while getting theorem 'bi1'."
     ]
    }
   ],
   "source": [
    "auc_vals = []\n",
    "for t in tqdm(theorem_list):\n",
    "    if t in database.propositions.keys():\n",
    "        auc_val = get_messed_prop_auc(t, obvious_clf.auc_score, 50, 20)\n",
    "        auc_vals.append(auc_val)\n",
    "    \n",
    "print(np.mean(auc_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d3e3843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 17/17 [00:12<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7645520140237883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "auc_vals = []\n",
    "for t in tqdm(theorem_list):\n",
    "    if t in database.propositions.keys():\n",
    "        auc_val = get_messed_prop_auc(t, weight_clf.auc_score, 50, 20)\n",
    "        auc_vals.append(auc_val)\n",
    "    \n",
    "print(np.mean(auc_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58c2feda",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1493545937.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/l2/7llyhwlx5nd60gwdz55p43cr0000gn/T/ipykernel_23994/1493545937.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    listar teoremas e tirar media das performances\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "listar teoremas e tirar media das performances\n",
    "verificar como computar metricas como numero de inferencias necessárias para cada passo\n",
    "\n",
    "\n",
    "provavelmente vou ter salvar a parte que importa do database em um pickle e dentro disso ir adicionando a quantidade de passos de prova para cada prova \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "277f9795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "876d0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database not found. Creating new database.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tdb = TheoremDatabase(\"tdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "80b8d39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c72c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d106b7d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LightProp' object has no attribute 'entails_proof_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l2/7llyhwlx5nd60gwdz55p43cr0000gn/T/ipykernel_23994/1249173556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dfss2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlp_proof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_proof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Volumes/GoogleDrive/My Drive/UFABC/Pesquisa/Community Detection for Granularity/mathview/expanding.py\u001b[0m in \u001b[0;36mconstruct_proof\u001b[0;34m(prop)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_proof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mroot_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentails_proof_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_construct_proof_recursive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LightProp' object has no attribute 'entails_proof_steps'"
     ]
    }
   ],
   "source": [
    "class LightProp:\n",
    "    def __init__(self, prop):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "\n",
    "lp = LightProp(database.propositions[\"dfss2\"])\n",
    "\n",
    "lp_proof = construct_proof(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d30c3667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16080"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(database.propositions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "87c3706d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tree: wi(wa(wph(),wb(wps(),wph())),wps())>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.propositions_list[1000].tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b1068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
